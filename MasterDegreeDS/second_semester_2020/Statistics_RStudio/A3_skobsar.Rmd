---
title: "A3_skobsar"
author: "Stefanie Kobsar"
date: "5/21/2020"
output:
   html_document:
      toc: yes
---

1.1. Modelo de regresi칩n lineal univariante

a) Estimar por m칤nimos cuadrados ordinarios un modelo lineal que explique la variable peso del beb칠 al nacer en funci칩n del di치metro abdominal antes de nacer.
Se evaluar치 la bondad del ajuste, a partir del coeficiente de determinaci칩n.
b) Posteriormente, se dividir치 la muestra en dos, seg칰n el sexo del beb칠 y se repetir치 el estudio para cada muestra por separado.Razonar los resultados.
```{r}
df_bw <-  read.csv("BWprocessed.csv") 
head(df_bw)
```

##### REGRESI칍N LINEAL #####

Se representa la variables peso del beb칠 en funci칩n del di치metro abdominal. Se representa un diagrama de dispersi칩n de ambas variables para poder determinar gr치ficamente la recta de ajuste y evaluar la bondad del mismo. 

```{r}
scatter.smooth(x=df_bw$AD, y=df_bw$BW, main="Peso beb칠 ~ Per칤metro abdominal")  # scatterplot
```

Se observa que puede existir una correlaci칩n lineal entre las dos variables. Para confirmarlo, hay que obtener los coeficientes de la recta de ajuste y el valor de R^2, que determina la calidad del ajuste. Se considera un buen ajuste a partir de R^2 >=0,90. 
```{r}
linearMod <- lm(AD ~ BW, data=df_bw) 
print(linearMod)
```
Se ha obtenido una recta de ajuste de la forma y = 0,01341x + 65,27981.

```{r}
summary(linearMod)
```
R^2=0,77 : El ajuste lineal no es significativo ya que R^2<0,90.

p-valor : Para una significancia del 95%, tendr칤a que ser un valor >1,96. Obtenemos un valor inferior a 1,96.

El valor predicitivo de la recta obtenida podr칤a ser mejorado con el an치lisis y descarte (siempre que sea posible) de los outliers. 

```{r}
boxplot(df_bw$AD)
```

```{r}
boxplot(df_bw$BW)
```
Los valores del set de datos se consideran extremos (outliers) cuando est치n fuera del rango en una proporci칩n de 1.5 veces del rango formado por los cuartiles m치s externos. Para valorar si es correcto eliminar los ouliers, hay que evaluar si es estad칤sitcamente correcto. Para ello existen m칰ltiples tests, y en este caso se usar치 el test de grubbs para realizar la evaluaci칩n. 

```{r}
library(outliers)

grubbs.test(df_bw$AD)

```

La hipotesis alternativa del test de Grubbs confirma significativamente que el valor 133mm  de AD es un outlier y se puede omitir. 

```{r}
grubbs.test(df_bw$BW)
```

La hipotesis alternativa del test de Grubbs confirma significativamente que el valor 4850g de BW es un outlier y se puede omitir. 


```{r}
df_ad <- df_bw$AD
match(c(133),df_ad)

df_BW <- df_bw$BW
match(c(4850),df_BW)
```
Se vuelve a realizar el ajuste omitiendo los outliers
```{r}

df_outlier <- data.frame(df_BW, df_ad)
df_outlier_2 <- df_outlier[-c(3,133), ] 
colnames(df_outlier_2) <- c("ADnew", "BWnew")
```

```{r}
scatter.smooth(x=df_outlier_2$ADnew, y=df_outlier_2$BWnew, main="Peso beb칠 ~ Per칤metro abdominal")  # scatterplot
```

```{r}
linearMod_2 <- lm(ADnew ~ BWnew , data=df_outlier_2) 
print(linearMod_2)

```

Se ha obtenido una recta de ajuste de la forma y = 56,82x + -3079,18.

```{r}
summary(linearMod_2)
```

Se observa que haber eliminado los valores significativamente fera de tendencia (y sus valores pares en las respectivas variables) no han hecho que mejore el ajuste ya que R^2 no ha sufrido pr치cticamente variaci칩n. 

El ajuste mediante una recta de regresi칩n se considera una buena primera aproximaci칩n ya que si que se puede observar una tendencia lineal, pero este tipo de ajuste no podemos considerarlo significativo ni concluyente de cara a construir un modelo predictivo ya que el valor de R^2 se queda lejos de ser aceptable para cumplir este prop칩sito.

######################################################

1.2. Modelo de regresi칩n lineal m칰ltiple (regresores cuantitativos)

a) Estimar por m칤nimos cuadrados ordinarios un modelo lineal que explique la variable peso del beb칠 en funci칩n del di치metro abdominal y el di치metro biparietal. Se proceder치 a evaluar la bondad de ajuste a trav칠s del coeficiente de determinaci칩n ajustado. 

Discutir si se produce una mejora del modelo.

b) Estudiar la existencia o no de multicolinealidad entre las covariables del modelo anterior, AD y BPD.

Ya hemos visto que existe una tendencia lineal entre BW y AD en el scatter plot de m치s arriba. Se hace el mismo an치lisis para BW en funci칩n de BPD.
```{r}
scatter.smooth(x=df_bw$BPD, y=df_bw$BW, main="Peso beb칠 ~ Di치metro biparietal")  # scatterplot
```

Se observa una ligera tendencia exponencial en la relaci칩n de estas dos variables. A continuaci칩n se analiza una posible multicolinealidad entre las covariables
```{r}
model_multi <- lm(log(df_bw$BPD)*df_bw$AD ~ df_bw$BW, data = df_bw)
plot(model_multi)
```

```{r}
print(model_multi)
```

```{r}
summary(model_multi)
```
Se observa que la relaci칩n entres BW y la covariable AD-BPD ha incrementado la bondad del ajuste. 

###########################################################

1.3. Modelo de regresi칩n lineal m칰ltiple (regresores cuantitativos y cualitativos)

a) Queremos conocer en qu칠 medida se relaciona el peso, en funci칩n del di치metro abdominal, di치metro biparietal y las semanas de gestaci칩n. Se recodificar치 la variable Ge,en menor y mayor o igual de 35 semanas. Aplicar un modelo de regresi칩n lineal m칰ltiple y explicar el resultado.

b) Ahora se calcular치 el modelo de regresi칩n lineal que relacione el peso con di치metro abdominal y di치metro biparietal, para la muestra cuyos beb칠s han nacido antes de las 35 semanas. Posteriormente,se calcular치 el mismo modelo, para los beb칠s nacidos en la semana 35 y posteriores. En vista a los resultados obtenidos,  existe relaci칩n con el apartado a)? Razonar la respuesta.

```{r}
#Variable Ge

df_ge_equal <- subset(df_bw, Ge == 35)
df_ge_minus <- subset(df_bw, Ge < 35)
df_ge_plus <- subset(df_bw, Ge > 35)

```
An치lisis peso - diametro abdominal - semanas de gestaci칩n = 35:

No existe ning칰n caso en el que las semanas de gestaci칩n hayan sido exactamente 35 semanas. 
```{r}
nrow(df_ge_equal)
```
An치lisis peso - diametro abdominal - semanas de gestaci칩n < 35:
```{r}
scatter.smooth(x=df_ge_minus$AD, y=df_ge_minus$BW, main="Peso beb칠 ~ Diametro abd [Ge<35]")  # scatterplot
```
```{r}
scatter.smooth(x=df_ge_plus$AD, y=df_ge_plus$BW, main="Peso beb칠 ~ Diametro abd [Ge>35]")  # scatterplot
```


```{r}
multi_ge_minus <- lm(df_ge_minus$AD ~ df_ge_minus$BW, data = df_ge_minus)
summary(multi_ge_minus)
```

An치lisis peso - diametro abdominal - semanas de gestaci칩n > 35:
```{r}
multi_ge_plus <- lm(df_ge_plus$AD ~ df_ge_plus$BW, data = df_ge_plus)
summary(multi_ge_plus)
```
```{r}
library(magrittr) 
library(dplyr)    
df_ge_dic <- df_bw
df_ge_dic <- df_ge_dic %>%
      mutate(Ge = ifelse(Ge < 35,0,1))

df_ge_dic_low <- subset(df_bw, Ge = 0)
df_ge_dic_high <- subset(df_bw, Ge = 0)

multi_gedic_low <- lm(df_ge_dic_low$AD ~ df_ge_dic_low$BW, data = df_ge_dic_low)
summary(multi_gedic_low)
```

```{r}
multi_gedic_high <- lm(df_ge_dic_high$AD ~ df_ge_dic_high$BW, data = df_ge_dic_high)
summary(multi_gedic_low)
```

Se observa un aumento en la bondad del modelo al partir el set de datos en dos categorias dicot칩micas(Ge<35 == 0, Ge=>35 ==1). Se observa una diferencia de 0.4 puntos entre el primer ajuste de BW-AD y el de ajuste con Ge configurada como variable dicot칩mica. 

Una explicaci칩n de esta diferencia puede ser que, al eliminar el detalle de la informaci칩n del peso y convertirlo en dos rangos, la variabilidad de los datos (desviaci칩n estandard) de la variable peso deja de afectar en el ajuste. Este tipo de decisiones en el tratamiento de datos y los consiguientes ajustes de regresi칩n son buenos como una primera aproximaci칩n en la b칰squeda de relaciones causales. Para comprobar la significancia 


###############################################################################

1.4. Diagnosis del modelo

Se tomar치 el modelo del apartado 1.2, que relaciona el peso del beb칠 en funci칩n del di치metro abdominal y eldi치metro biparietal.Para la diagnosis de este modelo se har치n dos gr치ficos: uno con los valores ajustados frente a los residuos (que nos permitir치 ver si la varianza es constante) y el gr치fico cuantil-cuantil que compara los residuos del modelo con los valores de una variable que se distribuye normalmente(QQ plot). 

Explicar conclusiones, a partir de los gr치ficos obtenidos.

Respuesta:

Se observa que al relacionar las variables AD-BPD mediante su multiplicaci칩n (y usando log(BPD) debido a la tendencia exponencial que mostraba en el gr치fico BW-BPD), se ve un aumento significativo del coeficiente de correlaci칩n hasta 0,81. De todas maneras, sigue sin ser un modelo lo suficientemente bueno como para poder ofrecer predictibilidad. 

Un posible soluci칩n ser칤a acotar el rango en el que actua la funci칩n para aumentar su predicibilidad. En el gr치fico Normal Q-Q del modelo desarrollado, se observa que la zona comprendida entre -1,5 y +1,5 del eje que representa los cuartiles te칩ricos representa unos datos m치s homogeneos en cuanto a su distribuci칩n normal. Es por ello que mediante un an치lisis de rangos (aumento de la sensibilidad del m칠todo) se podr칤a determinar el valor m칤nimo y m치ximo a partir de los cuales el valor predictivo del modelo deja de ser v치lido. Es posible que para un rango de pesos concreto encontrasemos un ajuste de bondad mayor. Esta propuesta se deja planteada pero no se desarrollar치 ya que, en mi opini칩n, excede el objetivo de la pr치ctica :).

####################### Modelo de regresi칩n log칤stica ######################

2.1. Estimaci칩n de OR (Odds Ratio)


a1) bajo peso vs madre fumadora

Se considera bajo peso BW<2,5kg


TABLA DE CONTINGENCIA:

```{r}
df_bw_yes_low <- subset(df_bw, BW < 2500 & Sm == "S")
df_bw_no_low <- subset(df_bw, BW < 2500 & Sm == "N")
df_bw_yes_high <- subset(df_bw, BW >= 2500 & Sm == "S")
df_bw_no_high <- subset(df_bw, BW >= 2500 & Sm == "N")

con1 <- nrow(df_bw_yes_low)
con2 <- nrow(df_bw_no_low)
con3 <- nrow(df_bw_yes_high)
con4 <- nrow(df_bw_no_high)

cont_table_fn <- function(con1, con2, con3, con4)
  {
  table_1 <- matrix(c(con1, con2, con3, con4), ncol=2, byrow=T)
  colnames(table_1) <- c("Variable 1 TRUE", "Variable 1 FALSE")
  rownames(table_1) <- c("Peso < 2,5kg", "Peso > 2,5kg")
  table <- as.table(table_1)
  tab <- cbind(table_1, Total = rowSums(table_1))
  cont_table <- rbind(tab, Total = colSums(tab))
  print(cont_table)}

table_1 <- cont_table_fn(con1, con2, con3, con4)
```

```{r}
chisq.test(table_1)
```

El valor obtenido de chi cuadrado es mayor al tabulado, por tanto, la hip칩tesis nula queda descartada. Se puede decir con un grado de significancia de un 95% que no existe relaci칩n entre bajo peso al nacer y el hecho de que la madre sea fumadora

###### ODD-RATIO ######

```{r}
odd_ratio_fn <- function(p)
  {
  odd_ratio <-  p/(1-p)
  return(odd_ratio)
  }

#odd ratio de peso bajo, fumadora
p1 = table_1[1]/table_1[7]
or_1 <- odd_ratio_fn(p1)
#odd ratio de peso bajo, no fumadora
p2 = table_1[4]/table_1[7]
or_2 <- odd_ratio_fn(p2)
#odd ratio de peso alto, fumadora
p3 = table_1[2]/table_1[8]
or_3 <- odd_ratio_fn(p3)
#odd ratio de peso alto, no fumadora
p4 = table_1[5]/table_1[8]
or_4 <- odd_ratio_fn(p4)
```

```{r}
OR_table <- function(or1, or2, or3, or4)
  {
  table_1 <- matrix(c(or1, or2, or3, or4), ncol=2, byrow=T)
  colnames(table_1) <- c("Variable 1 TRUE", "Variable 1 FALSE")
  rownames(table_1) <- c("Peso < 2,5kg", "Peso > 2,5kg")
  table <- as.table(table_1)
  return(table)}
OR_table(or_1, or_2, or_3, or_4)
```
El ratio de la probabilidad es directamente proporcional a la ocurrencia del evento estudiado. Un odd-ratio > 1 indica que es probable que se cumpla el valor que se estudia de una variable cuando est치 en presencia de otra variable. As칤, odd-ratio nos da la informaci칩n de cu치n fuertemente est치n relacionadas unas variables con otras. 

Madre fumadora tiene un odd-ratio=1,28 (OR>1). Por tanto la probabilidad en ocurrencia de tener un beb칠 que pese menos de 2,5kg en una madre fumadora es alta. 


a2) bajo peso vs sexo

##### TABLA CONTINGENCIA #####

```{r}
df_bw_F_low <- subset(df_bw, BW < 2500 & Sex == "F")
df_bw_M_low <- subset(df_bw, BW < 2500 & Sex == "M")
df_bw_F_high <- subset(df_bw, BW >= 2500 & Sex == "F")
df_bw_M_high <- subset(df_bw, BW >= 2500 & Sex == "M")

con1_sex <- nrow(df_bw_F_low)
con2_sex <- nrow(df_bw_M_low)
con3_sex <- nrow(df_bw_F_high)
con4_sex <- nrow(df_bw_M_high)

table_2 <- cont_table_fn(con1_sex, con2_sex, con3_sex, con4_sex)
```
```{r}
chisq.test(table_2)
```
p-value es mas grande de 0,05. Esto implica aceptar la hip칩tesis nula, en la que se postula que las varianzas de ambos sets de datos son iguales. Por tanto, no se puede realizar una comparaci칩n de ocurrencia (numero de casos con un determinado peso en funci칩n del sexo) ya que son variables dependientes. 

###### ODD RATIO ######

```{r}
#odd ratio de peso bajo, ni침a
p1_2 = table_2[1]/table_2[7]
or_1_2 <- odd_ratio_fn(p1_2)
#odd ratio de peso bajo, ni침o
p2_2 = table_2[4]/table_2[7]
or_2_2 <- odd_ratio_fn(p2_2)
#odd ratio de peso alto, ni침a
p3_2 = table_2[2]/table_2[8]
or_3_2 <- odd_ratio_fn(p3_2)
#odd ratio de peso alto, ni침o
p4_2 = table_2[5]/table_2[8]
or_4_2 <- odd_ratio_fn(p4_2)

OR_table(or_1_2, or_2_2, or_3_2, or_4_2)
```

Se calcula el OR a modo de ejemplo, sin 치nimo de interpretar la relaci칩n de ocurrencia entre las variables. Se observa que OR>1 para las ni침as tanto en peso <2,5kg y >2,5kg. Este dato carece de sentido ya que tiene una ocurrencia similar dos par치metros contrarios. Es por ello que no tiene sentido el an치lisis de las OR en este caso particular. 


a3) semanas de gestaci칩n (Ge), (Se dividir치 entre menor y mayor o igual de 35 semanas)

```{r}
#dataframe con Ge como variable dicot칩mica
df_ge_dic
#ge=0 bajo peso, ge=1 peso alto. 

df_bw_Ge_0 <- subset(df_ge_dic, BW < 2500 & Ge == 0)
df_bw_Ge_1 <- subset(df_ge_dic, BW < 2500 & Ge == 1)
df_bw_Ge_high_0 <- subset(df_ge_dic, BW >= 2500 & Ge == 0)
df_bw_Ge_high_1 <- subset(df_ge_dic, BW >= 2500 & Ge == 1)

con1_Ge <- nrow(df_bw_Ge_0)
con2_Ge <- nrow(df_bw_Ge_1)
con3_Ge <- nrow(df_bw_Ge_high_0)
con4_Ge <- nrow(df_bw_Ge_high_1)

table_3 <- cont_table_fn(con1_Ge, con2_Ge, con3_Ge, con4_Ge)
```

```{r}
chisq.test(table_3)
```
Se confirma H1, hipotesis en la que se plantea que las varianzas de ambos conjuntos de datos son significativamente diferentes y por lo tanto son variables independientes. 

 #### ODD RATIO #### 
 
```{r}
#odd ratio de peso bajo, Ge<35
p1_3 = table_3[1]/table_3[7]
or_1_3 <- odd_ratio_fn(p1_3)
#odd ratio de peso bajo, Ge>35
p2_3 = table_3[4]/table_3[7]
or_2_3 <- odd_ratio_fn(p2_3)
#odd ratio de peso alto, Ge<35
p3_3 = table_3[2]/table_3[8]
or_3_3 <- odd_ratio_fn(p3_3)
#odd ratio de peso alto, Ge>35
p4_3 = table_3[5]/table_3[8]
or_4_3 <- odd_ratio_fn(p4_3)

OR_table(or_1_3, or_2_3, or_3_3, or_4_3)
```
Se observa que hay una fuerte relaci칩n (OR >> 1)entre un beb칠 con menos de 35 semanas de gestaci칩n, como cab칤a esperar. Por otra parte, tambi칠n se observa una mayor ocurrencia que los beb칠s con m치s semanas de gestaci칩n presenten pesos mayores o iguales a 2,5kg. 

b) Si no se hubiese recodificado la variable semanas de gestaci칩n, 쯣odr칤amos seguir el procedimiento anterior para el c치lculo de la OR?. Explicar la respuesta.

No, porque la comparaci칩n de variables mediante una tabla de contingencia aplica para variables categ칩ricas y no continuas. 

c) Si queremos ver la relaci칩n entre bajo peso y lugar de procedencia, 쯣odr칤amos seguir el procedimiento anterior para el c치lculo de la OR? En el caso que la respuesta fuese negativa, 쯖u치l ser칤a una soluci칩n?.

Podriamos seguir el anterior procedimiento comparando el peso del beb칠 con cada pa칤s y determinar una relaci칩n ponderada entre los diferentes par치metros demogr치ficos y sociales relevantes en cada pa칤s. Para realizar un an치lisis conjunto de la misma variable y pa칤ses diferentes, previamente se tendr치 que haber construido un marco interpretativo com칰n en la que se pueda comparar los datos de los beb칠s, ya que si no fuese as칤, se podr칤a realizar una comparaci칩n sesgada. 

Una vez constriudo el marco com칰n, habria que limpiar los datos, normalizarlos y asegurarse que los datos restantes representen una muestra (N) lo suficientemente grande para llegar a una conlcusi칩n feaciente. 

Realmente es un an치lisis complicado, ya que cuando se trata de factores fisiol칩gicos humanos, solo determinar las variables independientes en cada grupo de poblaci칩n es ya en si mismo todo un reto. 

##################################################################################

2.2. Modelo de regresi칩n log칤stica

a) Estimar el modelo de regresi칩n log칤stica tomando como variable dependiente, tener bajo peso al nacer o no y siendo la variable explicativa, fumar o no. 쯇odemos considerar que el hecho de fumar es un factor de riesgo de bajo peso? Justifica tu respuesta. 쯊iene relaci칩n con lo obtenido en el apartado anterior?

```{r}
df_logit <- df_bw

library(dplyr)
df_logit <- df_logit %>%
      mutate(BW = ifelse(BW < 2500,0,1)) #Se configura la variable dependiente como 0, 1 para poder realizar el ajuste de regresi칩n log칤stica. 
df_logit <- df_logit %>%
      mutate(Ge = ifelse(Ge < 35,0,1))

RLOG_a <- glm(formula = BW~Sm, df_logit, family = binomial(link = "logit"))

summary(RLOG_a)

```

```{r}
#Estad칤stico de prueba

with(RLOG_a, null.deviance-deviance)
```
Test de significancia: chi cuadrado

Ho: modelo no sig
H1: modelo si sig
```{r}
#valor p del estad칤stico de prueba
with(RLOG_a, pchisq(null.deviance-deviance, df.null-df.residual, lower.tail=FALSE))
```
Como p-value es menor al valor tabulado, se acepta H1 y el modelo se considera significativo. 

Para evaluar en qu칠 medida afecta la variable Sm, hay que hacer el an치lsis de los coeficientes. El modelo nos devuelve los coeficientes en su modo logar칤tmico. Para interpretarlos sobre 1, se tiene que calcular la exponencial de dichos factores. 

```{r}
#C치lculo de Odd Ratio con los coeficientes de la ecuaci칩n de regresi칩n log칤stica
exp(coefficients(RLOG_a))
```
Cuando exp(coeficient) < 1, significa que la probabilidad de obtener un bebe con peso mayor a 2,5kg es baja. Cuanto m치s alejado esta el valor obtenido, menor es la probabilidad de 칠xito. En este caso, el valor obtenido es 0.008, lo que significa que la probabilidad de obtener un beb칠 con >2.5kg es muy baja si la madre es fumadora. 


b) A침adimos al modelo anterior las variable continua di치metro abdominal (AD). 쯉e observa una mejora del modelo? Explicar. Realizad tambi칠n el c치lculo de las OR y su intervalo de confianza.

```{r}
RLOG_b <- glm(formula = BW~AD+Sm, df_logit, family = binomial(link = "logit"))

summary(RLOG_b)
```

Test de significancia: chi cuadrado

Ho: modelo no sig
H1: modelo si sig

```{r}
#Estad칤stico de prueba

with(RLOG_b, null.deviance-deviance)

#valor p del estad칤stico de prueba
with(RLOG_b, pchisq(null.deviance-deviance, df.null-df.residual, lower.tail=FALSE))
```
Se rechaza Ho. El modelo es significativo. 

#### ODD RATIO ####

```{r}
exp(coefficients(RLOG_b))
```

OR(AD)=1,66
OR(Sm)=0,004

#### Intervalo de confianza ####






c) Ahora a침adimos al modelo anterior las variable City. Se tomar치 como ciudad de referencia Barcelona. C치lculo de las OR. 쯉e observa una mejora del modelo? Explicar.

```{r}
RLOG_c <- glm(formula = BW~AD+Sm+City, df_logit, family = binomial(link = "logit"))

summary(RLOG_c)
```

Test de significancia: chi cuadrado

Ho: modelo no sig
H1: modelo si sig

```{r}
#Estad칤stico de prueba

with(RLOG_b, null.deviance-deviance)

#valor p del estad칤stico de prueba
with(RLOG_b, pchisq(null.deviance-deviance, df.null-df.residual, lower.tail=FALSE))
```
Se rechaza Ho. El modelo es significativo. 

```{r}
exp(coefficients(RLOG_c))
```
ODD RATIOS: 

AD = 1.71
Sm = 0,003

Granada = 2,54
Madrid = 0,75
Pamplona = 2,15
Sevilla = 0,63
Valencia = 0,67

Se observa un ligero aumento en los OR de AD y Sm. Esto significa que estas variables tienen un peso ligeramente mayor en el modelo y que, al ser positivas, son directamente proporcionales a la variable de estudio.

Granada y Pamplona tienen un OR>1. Esto significa que los beb칠s nacidos en estas ciudades tienen m치s probabilidades de tener un peso >2,5kg segun el modelo. Por otro lado, Madrid, Sevilla y Valencia tienen un OR<1, con lo que la probabilidad de 칠xito, aunque proporcional, es baja.


#### Intervalo de confiaza ####
```{r}
exp(confint(RLOG_b))
```


####################################################################################

2.3. Predicci칩n

Seg칰n el modelo del apartado 2.2 b), 쯖u치l ser칤a la probabilidad de bajo peso al nacer, si la madre es fumadora y AD es de 90?

```{r}
summary(RLOG_b)
```

```{r}
#Ecuaci칩n del modelo: ln(pi/(1-pi))=-48,67005+0,50513*AD-5,60171*Sm
prob_peso_alto <- exp(c(-48.67005+0.50513*90-5.60171*1))
prob_peso_bajo <- c(1-prob_peso_alto)
prob_peso_bajo
```
La probabilidad de obtener un beb칠 de bajo peso con 40cm de di치metro abdominal y madre fumadora es de un 99,9%.

############################################

2.4. Bondad del ajuste

Usa el test de Hosman-Lemeshow para ver la bondad de ajuste del modelo final escogido. 
```{r}
#Escoger el modelo: An치lisis de coeficientes AIC
AIC_b <- AIC(RLOG_b)
AIC_c <- AIC(RLOG_c)

#el minimo valor de AIC lo tiene el modelo C

diff_aic_cb <- AIC_c-AIC_b
diff_aic_cb
```

if 풊洧녰<2, then there is substantial support for the 洧녰-th model (or the evidence against it is worth only a bare mention), and the proposition that it is a proper description is highly probable;

if 2<풊洧녰<4, then there is strong support for the 洧녰-th model;

if 4<풊洧녰<7, then there is considerably less support for the 洧녰-th model;
models with 풊洧녰>10 have essentially no support.


풊cb: 풊洧녰>7.Se escoge el modelo c frente al b.




```{r}
library(ResourceSelection)
hl_test <- hoslem.test(RLOG_c$y, fitted(RLOG_c), g=10)
hl_test
```

```{r}
cbind(hl_test$expected, hl_test$observed)
#El test funciona correctamente
```

###########################################

Curva ROC:

```{r}
library(pROC)
roc(df_logit$BW, RLOG_c$fitted.values, plot=TRUE, legacy.axes=TRUE, percent = TRUE, xlab="False Positive Precentage", ylab= "True Positive Perventage")
```

Output:

Data: RLOG_c$fitted.values in 107 controls (df_logit$BW 0) < 193 cases (df_logit$BW 1).

Area under the curve: 0.9816

Una curva de caracter칤sticas del operador receptor (ROC) es un gr치fico que se utiliza para mostrar la capacidad de diagn칩stico de los clasificadores binarios. 

Una curva ROC se construye trazando la tasa positiva verdadera (TPR) contra la tasa positiva falsa (FPR). La TPR es la proporci칩n de observaciones que se pronosticaron correctamente como positivas de todas las observaciones positivas (TP / (TP + FN)). Del mismo modo, la tasa de falsos positivos es la proporci칩n de observaciones que se predice incorrectamente que son positivas de todas las observaciones negativas (FP / (TN + FP)).

Un enfoque com칰n es calcular el 치rea bajo la curva ROC, que se abrevia a AUC. Es equivalente a la probabilidad de que una instancia positiva elegida al azar tenga una clasificaci칩n m치s alta que una instancia negativa elegida al azar. Por tanto, al haber obtenido un AUC de 98,16%, existe un 98,16% de probabilidad de obtener verdaderos positivos, frente a 1,84% de probabilidad de obtener un falso positivo. 


############################################################################

Conclusiones:

Se ha visto a lo largo de la pr치ctica multiples an치lisis de las variables del dataset proporcionado. 

Los an치lisis empleando regresi칩n lineal simple han permitido encontrar la relaci칩n de linearidad directa entre dos variables del dataset. Los resultados de cada uno de estos an치lisis se han comentado en cada apartado particular. Realizar regresiones lineales simples con variables de un dataset permite hacer una primera aproximaci칩n en el an치lisis de los datos, y asi poder ver posibles relaciones significativas y proporcionales. 

En la segunda parte de la pr치ctica se introduce el concepto de regresi칩n log칤stica, el cual permite determinar la probabilidad que tiene cada una de las variables en la variable de estudio elegid (y), en este caso BW. La variable y se codifica como categ칩rica y con ello es posible determinar el 칠xito o el fracaso en cada caso analizado.  Como en la primera parte, se han realizado y explicado las conclusiones los an치lisis de cada apartado particular. 

Se han analizado diferentes casos, utilizando un modelo para cada uno de ellos. Para finalizar el an치lisis, se han comparado los modelos utilizando el coeficiente AIC para escoger el de mejor ajuste y proceder a testearlo con el test de Hosman-Lemeshow. Finalmente, se ha analizado la curva ROC y su area bajo la curva. 

El test de H-L nos dice que el m칠todo escogido nos da una evidencia significativa en solo el 69% de los casos (pvalue=0,688).

Finalmente, la curva ROC nos dice que tenemos un 98% de probabilidades de obtener un verdadero positivo al usar el modelo escogido. 
